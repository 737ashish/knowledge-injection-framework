{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "beb76967-5207-4b17-b3c8-0ec81406434f",
   "metadata": {},
   "source": [
    "# Injection Accuracy Evaluation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "0e4f83f9-7eb3-4d0e-b2fe-07e386892c92",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import torch\n",
    "import pandas as pd\n",
    "import requests\n",
    "\n",
    "from scipy.spatial.distance import cosine\n",
    "from tqdm import tqdm\n",
    "from transformers import AutoModel, AutoModelForCausalLM, AutoModelForSequenceClassification, AutoTokenizer\n",
    "\n",
    "import sys\n",
    "sys.path.append(\"../utils\")\n",
    "from wikidata import load_wikidata_json"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "edbfb69e-fc3b-405f-a467-1a40797ac09c",
   "metadata": {},
   "outputs": [],
   "source": [
    "df = pd.read_json(\"../datasets/fewrel/fewrel_val.json\", lines=True)\n",
    "wikidata_dict = load_wikidata_json(\"../datasets/wikidata_entity_data.json\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "d1ac1470-030e-40a7-b5e2-29fe2ec3d14e",
   "metadata": {},
   "outputs": [],
   "source": [
    "# prepare dataset and add necessary columns\n",
    "# injected retrieved entity\n",
    "df[\"entity_retrieved\"] = df.apply(lambda row: row[row[\"cf_entity_type\"] + \"_retrieved\"], axis=1)\n",
    "df[\"id_entity_retrieved\"] = df.apply(lambda row: row[row[\"cf_entity_type\"] + \"_id\"], axis=1)\n",
    "# replace entity in full_text with injected retrieved entity\n",
    "df[\"full_text_retrieved\"] = df.apply(\n",
    "    lambda row: row[\"full_text\"].replace(row[row[\"cf_entity_type\"]], row[row[\"cf_entity_type\"] + \"_retrieved\"]), \n",
    "    axis=1)\n",
    "# retrieved == entity name in text\n",
    "df[\"match\"] = df.apply(lambda row: row[row[\"cf_entity_type\"]] == row[f\"{row['cf_entity_type']}_retrieved\"], axis=1)\n",
    "\n",
    "pos_samples = df[[\"full_text\", \"prompt\", \"h_retrieved\", \"r\", \"t_retrieved\", \"entity_retrieved\", \"id_entity_retrieved\", \"full_text_retrieved\", \"match\"]]\n",
    "pos_samples = pos_samples.rename(columns={\n",
    "    \"h_retrieved\": \"h\",\n",
    "    \"t_retrieved\": \"t\",\n",
    "    \"entity_retrieved\": \"injected_entity\", \n",
    "    \"id_entity_retrieved\": \"injected_entity_id\", \n",
    "    \"full_text_retrieved\": \"injected_entity_text\"})\n",
    "pos_samples[\"label\"] = 1\n",
    "\n",
    "neg_samples = df[[\"full_text\", \"prompt\", \"h_retrieved\", \"r\", \"t_retrieved\", \"cf_entity\", \"cf_id\", \"cf_full_text\", \"cf_entity_type\", \"match\"]]\n",
    "neg_samples = neg_samples.rename(columns={\n",
    "    \"h_retrieved\": \"h\",\n",
    "    \"t_retrieved\": \"t\",\n",
    "    \"cf_entity\": \"injected_entity\", \n",
    "    \"cf_id\": \"injected_entity_id\", \n",
    "    \"cf_full_text\": \"injected_entity_text\"})\n",
    "# replace correct triple entity with counterfactual entity\n",
    "neg_samples.loc[neg_samples[\"cf_entity_type\"] == \"t\", \"t\"] = neg_samples.loc[neg_samples[\"cf_entity_type\"] == \"t\", \"injected_entity\"]\n",
    "neg_samples.loc[neg_samples[\"cf_entity_type\"] == \"h\", \"h\"] = neg_samples.loc[neg_samples[\"cf_entity_type\"] == \"h\", \"injected_entity\"]\n",
    "neg_samples = neg_samples.drop(columns=\"cf_entity_type\", axis=1)\n",
    "neg_samples[\"label\"] = 0\n",
    "\n",
    "# 500 pos samples where entity exactly matches\n",
    "# 500 pos samples where entity are aliases\n",
    "# 500 neg samples with cf\n",
    "# 500 neg samples with no entity\n",
    "pos_samples_match = pos_samples[pos_samples[\"match\"]].head(500)\n",
    "pos_samples_alias = pos_samples[~pos_samples[\"match\"]].head(500)\n",
    "pos_samples = pd.concat([pos_samples_match, pos_samples_alias])\n",
    "\n",
    "neg_samples_cf = neg_samples.head(500)\n",
    "neg_samples_missing = neg_samples.iloc[500:1000].copy()\n",
    "neg_samples_missing[\"injected_entity_text\"] = neg_samples.apply(lambda row: row[\"injected_entity_text\"].replace(row[\"injected_entity\"], \"\"), axis=1)\n",
    "neg_samples = pd.concat([neg_samples_cf, neg_samples_missing])\n",
    "\n",
    "df_samples = pd.concat([pos_samples, neg_samples])\n",
    "df_samples = df_samples.reset_index(drop=True).reset_index().rename(columns={\"index\": \"id\"})"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ab7fe8d9-c12f-46d5-be19-0504dd952ae8",
   "metadata": {},
   "source": [
    "## Matching"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "913aa116-ef37-423b-bacc-8c3911150805",
   "metadata": {},
   "outputs": [],
   "source": [
    "def injection_acc_match(df, use_aliases=True):\n",
    "    correct_pred = 0\n",
    "    for _, row in df.iterrows():\n",
    "        gen = row[\"full_text\"][len(row[\"prompt\"]):]\n",
    "\n",
    "        if use_aliases:\n",
    "            aliases = wikidata_dict[row[\"injected_entity_id\"]][\"aliases\"]\n",
    "            if aliases:\n",
    "                aliases = set(sum([x.split(\", \") for x in aliases], []))\n",
    "        else:\n",
    "            aliases = None\n",
    "        \n",
    "        #if row[\"injected_entity\"].lower() in gen.lower() or (aliases and any([a.lower() in gen.lower() for a in aliases])):\n",
    "        # problem if case insensitive: e.g., Germany as alias DE, -> de might be machted in text because it appears in other words\n",
    "        if row[\"injected_entity\"] in gen or (aliases and any([a in gen for a in aliases])):\n",
    "            pred = 1\n",
    "        else:\n",
    "            pred = 0\n",
    "        correct_pred += pred == row[\"label\"]\n",
    "    return np.round(correct_pred / len(df), 4)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "039b5107-8ee1-45a7-8378-254bfdc2e5cb",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.87\n",
      "0.744\n",
      "1.0\n",
      "0.488\n",
      "0.996\n",
      "0.992\n",
      "1.0\n"
     ]
    }
   ],
   "source": [
    "print(injection_acc_match(df_samples))\n",
    "print(injection_acc_match(pos_samples, use_aliases=True))\n",
    "print(injection_acc_match(pos_samples_match, use_aliases=True))\n",
    "print(injection_acc_match(pos_samples_alias, use_aliases=True))\n",
    "print(injection_acc_match(neg_samples, use_aliases=True))\n",
    "print(injection_acc_match(neg_samples_cf, use_aliases=True))\n",
    "print(injection_acc_match(neg_samples_missing, use_aliases=True))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "416104e0-6296-47ef-9b65-b385e64d9b6d",
   "metadata": {},
   "source": [
    "## LLM prompt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "87f49f0f-c52a-49c5-8003-1487100521f4",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "bf330d91722f40a99725339ff8a42afa",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Loading checkpoint shards:   0%|          | 0/3 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "model_name = \"meta-llama/Llama-2-13b-chat-hf\"\n",
    "hf_token = \"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\"\n",
    "\n",
    "tokenizer = AutoTokenizer.from_pretrained(model_name, token=hf_token, padding_side=\"left\")\n",
    "tokenizer.pad_token = tokenizer.bos_token\n",
    "model = AutoModelForCausalLM.from_pretrained(model_name, device_map=\"auto\", load_in_4bit=True, token=hf_token, bnb_4bit_compute_dtype=torch.float16) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "1a597c07-d9d5-4440-b6a7-546dfb27ad25",
   "metadata": {},
   "outputs": [],
   "source": [
    "llama_chat_template = \"\"\"<s>[INST] <<SYS>>\n",
    "{system_prompt}\n",
    "<</SYS>>\n",
    "\n",
    "{user_message} [/INST] Answer:\"\"\"\n",
    "\n",
    "system_prompt = \"\"\"You are given a fact in the form of a (subject, predicate, object) triple and a sentence. Your task is to check if the given fact is present in the sentence.\n",
    "Answer only with 'Yes' or 'No'.\"\"\"\n",
    "\n",
    "user_message_template = \"\"\"Fact: ({h}, {r}, {t})\n",
    "Sentence: {sentence}\"\"\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "6298c5d7-4fc8-4f0e-8d2c-c1133d164750",
   "metadata": {},
   "outputs": [],
   "source": [
    "def injection_acc_llm(df, batch_size=32):\n",
    "    correct_pred = 0\n",
    "    total_rows = len(df)\n",
    "    prompts = []\n",
    "    batch_indices = []\n",
    "    idx_pos = tokenizer.encode(\"Yes\", add_special_tokens=False)[0]\n",
    "    idx_neg = tokenizer.encode(\"No\", add_special_tokens=False)[0]\n",
    "    \n",
    "    for n, row in df.reset_index(drop=True).iterrows():\n",
    "        user_message = user_message_template.format(h=row[\"h\"], r=row[\"r\"], t=row[\"t\"], sentence=row[\"full_text\"])\n",
    "        prompt = llama_chat_template.format(system_prompt=system_prompt, user_message=user_message)\n",
    "        prompts.append(prompt)\n",
    "        batch_indices.append(n)\n",
    "\n",
    "        if len(prompts) == batch_size or n == total_rows - 1:\n",
    "            inputs = tokenizer(prompts, padding=True, return_tensors=\"pt\").to(model.device)\n",
    "            with torch.no_grad():\n",
    "                outputs = model(**inputs).logits\n",
    "\n",
    "            for i, logits in enumerate(outputs):\n",
    "                # proba for Yes > proba for No\n",
    "                pred = 1 if logits[-1, idx_pos] > logits[-1, idx_neg] else 0\n",
    "                correct_pred += pred == df.iloc[batch_indices[i]][\"label\"]\n",
    "\n",
    "            print(f\"Steps: {n+1} - Acc: {correct_pred/(n+1):.4f}\")\n",
    "            prompts = []\n",
    "            batch_indices=[]\n",
    "    return correct_pred / total_rows"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "cc9b5213-e078-467f-be14-83a1017f53e4",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Steps: 32 - Acc: 0.9062\n",
      "Steps: 64 - Acc: 0.8594\n",
      "Steps: 96 - Acc: 0.8438\n",
      "Steps: 128 - Acc: 0.8594\n",
      "Steps: 160 - Acc: 0.8812\n",
      "Steps: 192 - Acc: 0.8802\n",
      "Steps: 224 - Acc: 0.8973\n",
      "Steps: 256 - Acc: 0.9062\n",
      "Steps: 288 - Acc: 0.9132\n",
      "Steps: 320 - Acc: 0.9187\n",
      "Steps: 352 - Acc: 0.9176\n",
      "Steps: 384 - Acc: 0.9167\n",
      "Steps: 416 - Acc: 0.9207\n",
      "Steps: 448 - Acc: 0.9129\n",
      "Steps: 480 - Acc: 0.9167\n",
      "Steps: 512 - Acc: 0.9180\n",
      "Steps: 544 - Acc: 0.9136\n",
      "Steps: 576 - Acc: 0.9115\n",
      "Steps: 608 - Acc: 0.9079\n",
      "Steps: 640 - Acc: 0.9062\n",
      "Steps: 672 - Acc: 0.9062\n",
      "Steps: 704 - Acc: 0.9020\n",
      "Steps: 736 - Acc: 0.8940\n",
      "Steps: 768 - Acc: 0.8893\n",
      "Steps: 800 - Acc: 0.8862\n",
      "Steps: 832 - Acc: 0.8870\n",
      "Steps: 864 - Acc: 0.8819\n",
      "Steps: 896 - Acc: 0.8817\n",
      "Steps: 928 - Acc: 0.8750\n",
      "Steps: 960 - Acc: 0.8729\n",
      "Steps: 992 - Acc: 0.8710\n",
      "Steps: 1024 - Acc: 0.8633\n",
      "Steps: 1056 - Acc: 0.8475\n",
      "Steps: 1088 - Acc: 0.8483\n",
      "Steps: 1120 - Acc: 0.8500\n",
      "Steps: 1152 - Acc: 0.8524\n",
      "Steps: 1184 - Acc: 0.8547\n",
      "Steps: 1216 - Acc: 0.8462\n",
      "Steps: 1248 - Acc: 0.8373\n",
      "Steps: 1280 - Acc: 0.8383\n",
      "Steps: 1312 - Acc: 0.8399\n",
      "Steps: 1344 - Acc: 0.8385\n",
      "Steps: 1376 - Acc: 0.8358\n",
      "Steps: 1408 - Acc: 0.8359\n",
      "Steps: 1440 - Acc: 0.8306\n",
      "Steps: 1472 - Acc: 0.8240\n",
      "Steps: 1504 - Acc: 0.8211\n",
      "Steps: 1536 - Acc: 0.8171\n",
      "Steps: 1568 - Acc: 0.8163\n",
      "Steps: 1600 - Acc: 0.8169\n",
      "Steps: 1632 - Acc: 0.8119\n",
      "Steps: 1664 - Acc: 0.8137\n",
      "Steps: 1696 - Acc: 0.8125\n",
      "Steps: 1728 - Acc: 0.8096\n",
      "Steps: 1760 - Acc: 0.8080\n",
      "Steps: 1792 - Acc: 0.8075\n",
      "Steps: 1824 - Acc: 0.8081\n",
      "Steps: 1856 - Acc: 0.8066\n",
      "Steps: 1888 - Acc: 0.8088\n",
      "Steps: 1920 - Acc: 0.8115\n",
      "Steps: 1952 - Acc: 0.8125\n",
      "Steps: 1984 - Acc: 0.8115\n",
      "Steps: 2000 - Acc: 0.8105\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "0.8105"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "injection_acc_llm(df_samples)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "34c09340-e661-467f-8df5-b52562fa8930",
   "metadata": {},
   "outputs": [],
   "source": [
    "# llama-2-13b-chat-hf 4bit: 0.7955\n",
    "# - bnb_4bit_compute_dtype=torch.float16: 0.7915 but waaaaay faster\n",
    "# - logits: 0.80875\n",
    "# llama-2-13b-chat-hf full precision: 0.8133\n",
    "# llama-2-70b-chat-hf 4bit: 0.7990"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "4091f668-b3e0-4672-aa18-d9704bad4be1",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Steps: 32 - Acc: 0.9062\n",
      "Steps: 64 - Acc: 0.8594\n",
      "Steps: 96 - Acc: 0.8438\n",
      "Steps: 128 - Acc: 0.8594\n",
      "Steps: 160 - Acc: 0.8812\n",
      "Steps: 192 - Acc: 0.8802\n",
      "Steps: 224 - Acc: 0.8973\n",
      "Steps: 256 - Acc: 0.9062\n",
      "Steps: 288 - Acc: 0.9132\n",
      "Steps: 320 - Acc: 0.9187\n",
      "Steps: 352 - Acc: 0.9176\n",
      "Steps: 384 - Acc: 0.9167\n",
      "Steps: 416 - Acc: 0.9207\n",
      "Steps: 448 - Acc: 0.9129\n",
      "Steps: 480 - Acc: 0.9167\n",
      "Steps: 512 - Acc: 0.9180\n",
      "Steps: 544 - Acc: 0.9136\n",
      "Steps: 576 - Acc: 0.9115\n",
      "Steps: 608 - Acc: 0.9079\n",
      "Steps: 640 - Acc: 0.9062\n",
      "Steps: 672 - Acc: 0.9062\n",
      "Steps: 704 - Acc: 0.9020\n",
      "Steps: 736 - Acc: 0.8940\n",
      "Steps: 768 - Acc: 0.8893\n",
      "Steps: 800 - Acc: 0.8862\n",
      "Steps: 832 - Acc: 0.8870\n",
      "Steps: 864 - Acc: 0.8819\n",
      "Steps: 896 - Acc: 0.8817\n",
      "Steps: 928 - Acc: 0.8750\n",
      "Steps: 960 - Acc: 0.8729\n",
      "Steps: 992 - Acc: 0.8710\n",
      "Steps: 1000 - Acc: 0.8720\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "0.872"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "injection_acc_llm(pos_samples)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "c0fd1afb-9300-43fe-b7cf-d6bca3bb1eb2",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Steps: 32 - Acc: 0.9062\n",
      "Steps: 64 - Acc: 0.8594\n",
      "Steps: 96 - Acc: 0.8438\n",
      "Steps: 128 - Acc: 0.8594\n",
      "Steps: 160 - Acc: 0.8812\n",
      "Steps: 192 - Acc: 0.8802\n",
      "Steps: 224 - Acc: 0.8973\n",
      "Steps: 256 - Acc: 0.9062\n",
      "Steps: 288 - Acc: 0.9132\n",
      "Steps: 320 - Acc: 0.9187\n",
      "Steps: 352 - Acc: 0.9176\n",
      "Steps: 384 - Acc: 0.9167\n",
      "Steps: 416 - Acc: 0.9207\n",
      "Steps: 448 - Acc: 0.9129\n",
      "Steps: 480 - Acc: 0.9167\n",
      "Steps: 500 - Acc: 0.9180\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "0.918"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "injection_acc_llm(pos_samples_match)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "08edfc94-d56c-480e-a5cd-805bd26e34e4",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Steps: 32 - Acc: 0.8750\n",
      "Steps: 64 - Acc: 0.8438\n",
      "Steps: 96 - Acc: 0.8750\n",
      "Steps: 128 - Acc: 0.8672\n",
      "Steps: 160 - Acc: 0.8688\n",
      "Steps: 192 - Acc: 0.8646\n",
      "Steps: 224 - Acc: 0.8438\n",
      "Steps: 256 - Acc: 0.8477\n",
      "Steps: 288 - Acc: 0.8333\n",
      "Steps: 320 - Acc: 0.8375\n",
      "Steps: 352 - Acc: 0.8381\n",
      "Steps: 384 - Acc: 0.8333\n",
      "Steps: 416 - Acc: 0.8245\n",
      "Steps: 448 - Acc: 0.8281\n",
      "Steps: 480 - Acc: 0.8250\n",
      "Steps: 500 - Acc: 0.8260\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "0.826"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "injection_acc_llm(pos_samples_alias)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "69da34f7-eddf-40c8-9c09-f327258bfb1b",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Steps: 32 - Acc: 0.3750\n",
      "Steps: 64 - Acc: 0.4844\n",
      "Steps: 96 - Acc: 0.6146\n",
      "Steps: 128 - Acc: 0.6797\n",
      "Steps: 160 - Acc: 0.7375\n",
      "Steps: 192 - Acc: 0.7552\n",
      "Steps: 224 - Acc: 0.7143\n",
      "Steps: 256 - Acc: 0.6953\n",
      "Steps: 288 - Acc: 0.7257\n",
      "Steps: 320 - Acc: 0.7406\n",
      "Steps: 352 - Acc: 0.7415\n",
      "Steps: 384 - Acc: 0.7422\n",
      "Steps: 416 - Acc: 0.7500\n",
      "Steps: 448 - Acc: 0.7277\n",
      "Steps: 480 - Acc: 0.7208\n",
      "Steps: 512 - Acc: 0.7148\n",
      "Steps: 544 - Acc: 0.7188\n",
      "Steps: 576 - Acc: 0.7153\n",
      "Steps: 608 - Acc: 0.7220\n",
      "Steps: 640 - Acc: 0.7203\n",
      "Steps: 672 - Acc: 0.7262\n",
      "Steps: 704 - Acc: 0.7259\n",
      "Steps: 736 - Acc: 0.7242\n",
      "Steps: 768 - Acc: 0.7240\n",
      "Steps: 800 - Acc: 0.7262\n",
      "Steps: 832 - Acc: 0.7296\n",
      "Steps: 864 - Acc: 0.7315\n",
      "Steps: 896 - Acc: 0.7400\n",
      "Steps: 928 - Acc: 0.7468\n",
      "Steps: 960 - Acc: 0.7510\n",
      "Steps: 992 - Acc: 0.7500\n",
      "Steps: 1000 - Acc: 0.7490\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "0.749"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "injection_acc_llm(neg_samples)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "b61c07f4-87e8-495c-9abc-72cdb4540fef",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Steps: 32 - Acc: 0.3750\n",
      "Steps: 64 - Acc: 0.4844\n",
      "Steps: 96 - Acc: 0.6146\n",
      "Steps: 128 - Acc: 0.6797\n",
      "Steps: 160 - Acc: 0.7375\n",
      "Steps: 192 - Acc: 0.7552\n",
      "Steps: 224 - Acc: 0.7143\n",
      "Steps: 256 - Acc: 0.6953\n",
      "Steps: 288 - Acc: 0.7257\n",
      "Steps: 320 - Acc: 0.7406\n",
      "Steps: 352 - Acc: 0.7415\n",
      "Steps: 384 - Acc: 0.7422\n",
      "Steps: 416 - Acc: 0.7500\n",
      "Steps: 448 - Acc: 0.7277\n",
      "Steps: 480 - Acc: 0.7208\n",
      "Steps: 500 - Acc: 0.7200\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "0.72"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "injection_acc_llm(neg_samples_cf)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "bdfef83b-34b4-47d2-a998-8fb7f6739797",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Steps: 32 - Acc: 0.5938\n",
      "Steps: 64 - Acc: 0.6875\n",
      "Steps: 96 - Acc: 0.7396\n",
      "Steps: 128 - Acc: 0.6953\n",
      "Steps: 160 - Acc: 0.7438\n",
      "Steps: 192 - Acc: 0.7448\n",
      "Steps: 224 - Acc: 0.7321\n",
      "Steps: 256 - Acc: 0.7305\n",
      "Steps: 288 - Acc: 0.7361\n",
      "Steps: 320 - Acc: 0.7469\n",
      "Steps: 352 - Acc: 0.7415\n",
      "Steps: 384 - Acc: 0.7578\n",
      "Steps: 416 - Acc: 0.7740\n",
      "Steps: 448 - Acc: 0.7835\n",
      "Steps: 480 - Acc: 0.7854\n",
      "Steps: 500 - Acc: 0.7780\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "0.778"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "injection_acc_llm(neg_samples_missing)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fa77c705-453d-433c-bf87-180bead36ebf",
   "metadata": {},
   "source": [
    "## Embedding similartiy"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "e681ce24-41e6-4fd9-bacb-b1720f40d632",
   "metadata": {},
   "outputs": [],
   "source": [
    "def mean_pooling(model_output, attention_mask):\n",
    "    # Mean Pooling - Take attention mask into account for correct averaging\n",
    "    token_embeddings = model_output[0] # First element of model_output contains all token embeddings\n",
    "    input_mask_expanded = attention_mask.unsqueeze(-1).expand(token_embeddings.size()).float()\n",
    "    return torch.sum(token_embeddings * input_mask_expanded, 1) / torch.clamp(input_mask_expanded.sum(1), min=1e-9)\n",
    "\n",
    "def cosine_sim(sentences):\n",
    "    encoded_input = tokenizer(sentences, padding=True, truncation=True, return_tensors=\"pt\").to(\"cuda\")\n",
    "    with torch.no_grad():\n",
    "        model_output = model(**encoded_input)\n",
    "    embeddings = mean_pooling(model_output, encoded_input[\"attention_mask\"])\n",
    "    embeddings = torch.nn.functional.normalize(embeddings, p=2, dim=1).cpu()\n",
    "    return 1 - cosine(embeddings[0], embeddings[1])\n",
    "\n",
    "tokenizer = AutoTokenizer.from_pretrained(\"sentence-transformers/all-mpnet-base-v2\")\n",
    "model = AutoModel.from_pretrained(\"sentence-transformers/all-mpnet-base-v2\").to(\"cuda\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "957d890c-94eb-4e5c-b014-c974abebe7d7",
   "metadata": {},
   "outputs": [],
   "source": [
    "def injection_acc_embd(df):\n",
    "    score = 0\n",
    "    for _, row in tqdm(df.iterrows(), total=len(df)):\n",
    "        #pred = cosine_sim([row[\"full_text\"], row[\"injected_entity_text\"]])\n",
    "        pred = cosine_sim([row[\"full_text\"][len(row[\"prompt\"]):], row[\"injected_entity_text\"][len(row[\"prompt\"]):]])\n",
    "        pred = 0 if pred < 0.8 else 1 # threshold\n",
    "        score += 1 if pred == row[\"label\"] else 0\n",
    "    return score / len(df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "4049dfb5-4b1a-4eec-9726-a64e399ea62d",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 2000/2000 [00:16<00:00, 123.67it/s]\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "0.8215"
      ]
     },
     "execution_count": 21,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "injection_acc_embd(df_samples)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "6ca86d07-185a-43fa-86bd-cc5bcae02751",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 1000/1000 [00:06<00:00, 144.08it/s]\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "0.86"
      ]
     },
     "execution_count": 22,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "injection_acc_embd(pos_samples)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "18df891b-4845-4a03-9ac0-e45b7c37d560",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 500/500 [00:03<00:00, 144.56it/s]\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "1.0"
      ]
     },
     "execution_count": 23,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "injection_acc_embd(pos_samples_match)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "fa91b80e-37a3-44b2-85db-5392fee6d4cf",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 500/500 [00:03<00:00, 143.41it/s]\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "0.72"
      ]
     },
     "execution_count": 24,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "injection_acc_embd(pos_samples_alias)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "7393e54d-91dc-4da0-ad83-10a1c1bc79c9",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 1000/1000 [00:06<00:00, 144.18it/s]\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "0.783"
      ]
     },
     "execution_count": 25,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "injection_acc_embd(neg_samples)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "4b3214be-e2a8-4148-819e-3ee7dbf99800",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 500/500 [00:03<00:00, 143.94it/s]\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "0.852"
      ]
     },
     "execution_count": 26,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "injection_acc_embd(neg_samples_cf)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "id": "f034dfcc-532c-4ce1-b0ed-75a5a90c70db",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 500/500 [00:03<00:00, 145.21it/s]\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "0.714"
      ]
     },
     "execution_count": 27,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "injection_acc_embd(neg_samples_missing)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "aa66aa76-4e4e-4c87-ab89-669f64ff869f",
   "metadata": {},
   "source": [
    "## Entailment Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "id": "f780dee4-89d8-4cca-9110-6aad4cd96870",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some weights of the model checkpoint at roberta-large-mnli were not used when initializing RobertaForSequenceClassification: ['roberta.pooler.dense.weight', 'roberta.pooler.dense.bias']\n",
      "- This IS expected if you are initializing RobertaForSequenceClassification from the checkpoint of a model trained on another task or with another architecture (e.g. initializing a BertForSequenceClassification model from a BertForPreTraining model).\n",
      "- This IS NOT expected if you are initializing RobertaForSequenceClassification from the checkpoint of a model that you expect to be exactly identical (initializing a BertForSequenceClassification model from a BertForSequenceClassification model).\n"
     ]
    }
   ],
   "source": [
    "tokenizer = AutoTokenizer.from_pretrained(\"roberta-large-mnli\")\n",
    "model = AutoModelForSequenceClassification.from_pretrained(\"roberta-large-mnli\").to(\"cuda\")\n",
    "\n",
    "def entailment(text):\n",
    "    inputs = tokenizer(text, return_tensors=\"pt\").to(\"cuda\")\n",
    "    with torch.no_grad():\n",
    "        output = model(**inputs)\n",
    "    # 1 if proba for entailment > proba for contradiction\n",
    "    return 1 if output.logits[0][0] < output.logits[0][2] else 0 "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "id": "59544fef-0952-4b98-947b-1c3497e4669e",
   "metadata": {},
   "outputs": [],
   "source": [
    "def injection_acc_entail(df):\n",
    "    correct_pred = 0\n",
    "    for _, row in tqdm(df.iterrows(), total=len(df)):\n",
    "        sentences = row[\"full_text\"] + \" \" + row[\"injected_entity_text\"]\n",
    "        pred = entailment(sentences)\n",
    "        correct_pred += pred == row[\"label\"]\n",
    "    return correct_pred / len(df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "id": "cbbb39e0-34bd-4e6d-af77-a9e98f8eb830",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 2000/2000 [00:25<00:00, 78.12it/s]\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "0.721"
      ]
     },
     "execution_count": 30,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "injection_acc_entail(df_samples)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "id": "2ebe7c59-9565-49f4-89ea-79e72afbb3ed",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 1000/1000 [00:12<00:00, 78.51it/s]\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "0.95"
      ]
     },
     "execution_count": 31,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "injection_acc_entail(pos_samples)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "id": "6f5e9b69-b33f-4f7c-922a-42f9ffd09c10",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 500/500 [00:06<00:00, 78.43it/s]\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "1.0"
      ]
     },
     "execution_count": 32,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "injection_acc_entail(pos_samples_match)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "id": "dded6c36-d7df-4af6-a684-a5f94ff4e3ab",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 500/500 [00:06<00:00, 77.56it/s]\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "0.9"
      ]
     },
     "execution_count": 33,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "injection_acc_entail(pos_samples_alias)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "id": "e9b426cf-7501-4e28-9c94-aa94c1c23a11",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 1000/1000 [00:12<00:00, 77.76it/s]\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "0.492"
      ]
     },
     "execution_count": 34,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "injection_acc_entail(neg_samples)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "id": "cd452527-d623-4117-bd55-9ff9f1695761",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 500/500 [00:06<00:00, 77.54it/s]\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "0.94"
      ]
     },
     "execution_count": 35,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "injection_acc_entail(neg_samples_cf)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "id": "011af3be-48e2-4498-9bd9-979482c85f17",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 500/500 [00:06<00:00, 78.02it/s]\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "0.044"
      ]
     },
     "execution_count": 36,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "injection_acc_entail(neg_samples_missing)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9d4f9ec6-bc6a-4fb5-acff-ad8f2d1c4f8e",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
